# Service Info

## Common use cases

The Cilium Tetragon integration allows users to ingest eBPF-based security observability and runtime enforcement data into the Elastic Stack. By leveraging eBPF, Tetragon provides deep visibility into kernel-level events with minimal performance overhead, enabling security teams to monitor and secure Linux workloads in real-time.

1.  **Runtime Security Monitoring:** Detect unauthorized process executions, suspicious binary usage, and privilege escalation attempts across host systems and Kubernetes clusters. It captures detailed process metadata including UID, GID, and process ancestry.
2.  **Network Observability:** Track network connection attempts (TCP/UDP), socket operations, and traffic patterns at the kernel level. This is crucial for identifying lateral movement, unauthorized external connections, or potential data exfiltration.
3.  **File Integrity Monitoring (FIM):** Monitor sensitive configuration files (e.g., `/etc/shadow`, `/etc/kubernetes/admin.conf`), binaries, and system paths. The integration captures unauthorized access, modification, or deletion events in real-time.
4.  **Container Escape Detection:** Monitor for activities that indicate a container breakout, such as unauthorized access to the host namespace, mounting of sensitive host paths, or manipulation of kernel structures.
5.  **Compliance and Auditing:** Maintain a comprehensive, immutable audit trail of all system-level activities. This data supports regulatory requirements like PCI-DSS, SOC2, and HIPAA by providing verifiable logs of who did what and when.

## Data types collected

This integration collects structured JSON logs from the Tetragon agent, which are processed into the `cilium_tetragon.log` data stream. This data stream includes:

-   **Process Lifecycle Events (`process_exec`, `process_exit`):** Logs containing execution details. These include visibility into process ancestry (parent/child relationships), execution arguments (**tetragon.process.arguments**), and environment variables.
-   **Network Connection Events (`tcp_connect`, `tcp_close`, `tcp_sendmsg`):** Detailed logs for socket operations and UDP traffic metadata, providing source/destination IPs and ports to track network flow.
-   **File System Events:** Logs related to file access (open, read, write) based on configured **TracingPolicies**, identifying which process accessed which file path.
-   **Privilege Events:** Monitoring of `setuid`, `setgid`, and other capability changes that might indicate privilege escalation or misuse of administrative rights.
-   **TracingPolicy Events:** Custom events generated by user-defined eBPF probes (kprobes, tracepoints, uprobes) specified in Tetragon's YAML-based policies.
-   **Default log path:** The integration defaults to watching `/var/log/tetragon/tetragon.log*`.

## Compatibility

This integration is compatible with the following versions and environments:
-   **Cilium Tetragon:** Versions 0.10.x and higher.
-   **Linux Kernel:** Version 4.19 or later (5.4+ is highly recommended for advanced features like FIM and network observability).
-   **Elastic Stack:** Version 8.12.0 or higher is required for full field mapping and dashboard compatibility.
-   **Architectures:** x86_64 and ARM64 architectures are supported.

## Scaling and Performance

-   **Kernel-level Filtering:** Tetragon uses eBPF to filter events directly in the kernel. This prevents "log storms" by ensuring only events matching your TracingPolicies are sent to userspace, significantly lowering CPU overhead compared to traditional auditing tools.
-   **High-Throughput Log Rotation:** In high-volume environments, Tetragon should be configured with `export-file-max-size-mb` (e.g., `100`) and `export-file-max-backups` (e.g., `5`) to manage local disk usage effectively.
-   **Resource Management:** In Kubernetes, the Tetragon DaemonSet should have resource limits defined (e.g., `512Mi` RAM and `500m` CPU) to ensure stability during peak system activity.
-   **Elastic Agent Performance:** Use the **Custom configurations** block in the integration settings to adjust the following variables if monitoring thousands of ephemeral log files:
    -   `ignore_older`: Helps the agent ignore files that haven't been modified for a specific duration.
    -   `close_inactive`: Closes the file handler after a period of inactivity to free up system resources.

# Set Up Instructions

## Vendor prerequisites

1.  **Administrative Access:** Root or sudo permissions on the host system to install the Tetragon daemon and configure the export paths.
2.  **eBPF Support:** A Linux kernel version of 4.19 or newer.
3.  **BTF Configuration:** Kernel must be compiled with `CONFIG_DEBUG_INFO_BTF=y`. You can verify this by checking if `/sys/kernel/btf/vmlinux` exists.
4.  **Directory Permissions:** The directory for log exports (e.g., `/var/log/tetragon/`) must be writeable by the `tetragon` user/group and readable by the `elastic-agent`.
5.  **Resource Allocation:** Ensure the host has at least 512MB of RAM dedicated to Tetragon for internal eBPF map handling and JSON encoding.

## Elastic prerequisites

1.  **Elastic Stack:** An active Elastic Stack deployment (version 8.12.0 or higher).
2.  **Elastic Agent:** An Elastic Agent must be installed on the target host or as a DaemonSet in Kubernetes.
3.  **Fleet Management:** The agent must be enrolled in Fleet and assigned to a valid agent policy.
4.  **Network Connectivity:** The agent requires local filesystem access to read the JSON logs generated by Tetragon.

## Vendor set up steps

### For JSON Log Export (Standard Linux Host):

1.  **Configure Log Export:** Create or edit the Tetragon configuration file at `/etc/tetragon/tetragon.yaml`.
2.  **Define Export Path:** Add the following configuration to enable structured JSON logging:
    ```yaml
    export-filename: "/var/log/tetragon/tetragon.log"
    ```
3.  **Configure Log Rotation:** Add rotation settings to prevent disk exhaustion:
    ```yaml
    export-file-max-size-mb: 100
    export-file-max-backups: 5
    export-file-compress: true
    ```
4.  **Apply Tracing Policies:** Ensure at least one TracingPolicy is active in `/etc/tetragon/conf.d/` to generate event data.
5.  **Restart Service:** Apply the configuration changes by running `sudo systemctl restart tetragon`.
6.  **Verify Export:** Confirm logs are generating correctly by running `sudo tail -f /var/log/tetragon/tetragon.log`.

### For Kubernetes (DaemonSet):

1.  **Update Helm Values:** Modify your `values.yaml` for the Tetragon Helm chart to ensure logs are exported to a host path:
    ```yaml
    tetragon:
      exportFilename: "/var/log/tetragon/tetragon.log"
      extraVolumes:
        - name: var-log-tetragon
          hostPath:
            path: /var/log/tetragon
            type: DirectoryOrCreate
      extraVolumeMounts:
        - name: var-log-tetragon
          mountPath: /var/log/tetragon
    ```
2.  **Apply Changes:** Upgrade your installation using `helm upgrade tetragon cilium/tetragon -f values.yaml`.
3.  **Elastic Agent Mount:** Ensure the Elastic Agent DaemonSet manifest includes a `hostPath` mount for `/var/log/tetragon` so the agent can access the log files from the host.

## Kibana set up steps

1.  In Kibana, navigate to **Management** > **Fleet** > **Integrations**.
2.  Search for and select **Cilium Tetragon**.
3.  Click **Add Cilium Tetragon**.
4.  Configure the following integration settings:
    -   **Log file path**: Specify the absolute path to your Tetragon JSON logs. For example: `/var/log/tetragon/tetragon.log*`.
    -   **Exclude files**: (Optional) Provide a list of patterns to exclude specific log files from being ingested.
    -   **Ignore older**: (Optional) Set a duration (e.g., `24h`) to ignore files that have not been modified.
    -   **Custom configurations**: (Optional) Add additional Filebeat processors or settings in YAML format.
5.  Select the **Existing Policy** where your target Elastic Agents are enrolled or create a new one.
6.  Click **Save and continue**. Fleet will automatically deploy the updated configuration to the selected agents.

# Validation Steps

### 1. Trigger Data Flow on Tetragon
Generate sample events to verify that the eBPF probes are active and logging:
1.  **Process Execution:** Run `whoami` or `ls /root` to trigger a `process_exec` event.
2.  **Network Activity:** Generate a network connection:
    ```bash
    curl --silent https://www.elastic.co/guide/index.html > /dev/null
    ```
3.  **Sudo Activity:** Run `sudo -l` to trigger privilege-related logs.
4.  **Verify Local File:** Check that JSON entries are appearing in the log file:
    ```bash
    sudo grep "process_exec" /var/log/tetragon/tetragon.log | tail -n 1
    ```

### 2. Check Data in Kibana
1.  **Navigate to Discover:** Go to **Analytics** > **Discover**.
2.  **Apply Filter Query:** In the KQL search bar, enter:
    `data_stream.dataset : "cilium_tetragon.log"`
3.  **Verify Fields:** Inspect the incoming documents to ensure the following fields are present and populated:
    *   `tetragon.process.binary`: Should contain paths like `/usr/bin/curl` or `/usr/bin/whoami`.
    *   `tetragon.process.arguments`: Should capture command-line flags.
    *   `event.action`: Should show actions like `process_exec`, `process_exit`, or `connect`.
    *   `host.name`: Confirm this matches the source machine.
4.  **View Dashboard:** Navigate to **Analytics** > **Dashboards** and open the **[Cilium Tetragon] Overview** dashboard to see visualized metrics and events.

# Troubleshooting

## Common Configuration Issues

-   **Log Path Mismatch:** If no logs appear in Kibana, verify that the path in your `tetragon.yaml` (`export-filename`) matches the **Log file path** in the Kibana integration settings.
-   **Permission Denied:** The Elastic Agent must have read access to the logs. Run `ls -l /var/log/tetragon/` to check permissions.
-   **Missing BTF Info:** If Tetragon fails to load eBPF programs, check system logs using `journalctl -u tetragon`. If you see "BTF not found", you may need to install the `pahole` package or provide a BTF file manually via the `--btf` flag.
-   **Kernel Version Too Old:** If network events are missing but process events work, verify your kernel version is at least 5.4. Older kernels have limited support for certain network hooks.

## Ingestion Errors

-   **JSON Parsing Failures:** Ensure Tetragon is not configured with `--export-format compact`. The integration requires the standard, multi-line JSON export format.
-   **Empty Logs:** If the log file exists but is empty, ensure you have applied a `TracingPolicy`. Tetragon does not log most events by default unless a policy is defined in `/etc/tetragon/conf.d/`.
-   **Agent Resource Constraints:** If logs are delayed, check if the Elastic Agent is being throttled. Increase the memory limit for the agent in your Kubernetes deployment if necessary.

## Vendor Resources

-   [Tetragon Official Documentation: Daemon Configuration](https://tetragon.io/docs/reference/daemon-configuration/)
-   [Tetragon Installation Guide for Kubernetes](https://tetragon.io/docs/getting-started/install-k8s/)
-   [Tetragon TracingPolicy Reference and Examples](https://tetragon.io/docs/concepts/tracing-policy/)
-   Tetragon GitHub Discussions

# Documentation sites

-   [Elastic Guide: Monitor logs from Elastic Agent](https://www.elastic.co/docs/solutions/observability/logs/explore-logs)
-   [Elastic Guide: Fleet Overview](https://www.elastic.co/docs/reference/fleet)
-   [Isovalent Blog: Real-time Runtime Security with Tetragon](https://isovalent.com/blog/post/2022-05-16-tetragon/)
-   [Tetragon GitHub: Examples of TracingPolicies](https://github.com/cilium/tetragon/tree/main/examples/tracingpolicy)