# Service Info

## Common use cases

The TCP integration allows the Elastic Agent to act as a listener, opening a specific network port to receive log data streamed over the Transmission Control Protocol (TCP). This is a highly flexible integration used to ingest data from systems that lack native Elastic modules but support standard network streaming.
- **Custom Application Logging:** Centralize logs from proprietary Java, Python, or Go applications that use socket appenders (like Log4j2 or Logback) to stream events directly to a collector.
- **Legacy System Integration:** Collect events from older hardware, mainframes, or specialized network appliances that do not support modern APIs or Syslog protocols but can output text streams to a network destination.
- **JSON Event Ingestion:** Ingest highly structured data from microservices and cloud-native applications that output newline-delimited JSON objects over a persistent TCP connection.
- **Internal Log Forwarding:** Act as an intermediate ingestion point for internal scripts or automated cron jobs that need to push status updates or error logs to the Elastic Stack without writing to local files.

## Data types collected

This integration can collect the following types of data:
- **Raw System Logs:** Standard plaintext logs generated by operating systems or hardware devices.
- **Structured Data (JSON):** Objects transmitted as single-line JSON strings, which can be automatically parsed into individual fields within Elasticsearch.
- **Common Event Format (CEF):** Security events formatted according to the CEF standard, often used by network security vendors.
- **Delimited Events:** Log streams where individual records are separated by specific characters, such as a newline (`\n`) or a null character (`\0`).
- **Network Metadata:** Information about the connection itself, including the source IP address and port of the system sending the logs.

## Compatibility

The **TCP Integration** is compatible with any external system, application, or library capable of establishing a standard TCP socket connection.
- **Elastic Agent:** Compatible with version 7.x and 8.x.
- **Operating Systems:** Supported on all platforms where Elastic Agent can be deployed, including Linux, Windows, and macOS.

## Scaling and Performance

- **Transport/Collection Considerations:** Unlike UDP, TCP provides a reliable transport mechanism with error checking and guaranteed delivery. However, this reliability introduces overhead due to the three-way handshake and acknowledgment packets. In high-latency environments, TCP windowing may impact throughput. Users should ensure the network path between the source and the Agent is stable to avoid connection resets that could lead to data loss during the reconnection window.
- **Data Volume Management:** To prevent overwhelming the Elastic Stack, it is recommended to filter logs at the source whenever possible. This includes setting the appropriate logging levels (e.g., `INFO` or `WARN` instead of `DEBUG`) and excluding verbose or redundant event types. If the source system generates high bursts of data, ensure the source has sufficient buffering capacity, as TCP backpressure will occur if the Elastic Agent cannot ingest data as fast as it is being sent.
- **Elastic Agent Scaling:** A single Elastic Agent can handle thousands of events per second via TCP, but performance is heavily dependent on the complexity of any ingest pipelines (e.g., Grok parsing or JSON decoding). For high-volume environments exceeding 10,000 events per second, it is recommended to deploy multiple Agents behind a network load balancer to distribute the TCP connection load and provide high availability.

# Set Up Instructions

## Vendor prerequisites

- **Administrative Access:** You must have the authority to modify the configuration of the source application or device (e.g., access to `log4j2.xml` or the device's management CLI).
- **Network Visibility:** The source system must have a clear network path to the host running the Elastic Agent.
- **Port Availability:** Ensure the chosen TCP port (e.g., 9002) is not already in use by another service on the Elastic Agent host.
- **Firewall Permissions:** Any intermediate firewalls, Network Access Control Lists (ACLs), or Security Groups must be configured to allow inbound TCP traffic on the designated port.
- **Formatting Requirements:** Knowledge of whether the source system sends plain text or structured JSON is required to properly configure the integration's parsing settings.

## Elastic prerequisites

- **Active Elastic Agent:** An Elastic Agent must be installed on a host and successfully enrolled in a Fleet policy.
- **Connectivity:** The Elastic Agent host must have network connectivity to the Elastic Stack (Elasticsearch and Kibana) to ship the collected logs.
- **Policy Management:** Permissions to edit Agent Policies in Kibana are required to add and configure the TCP integration.

## Vendor set up steps

### For Custom Application or Network Device Collection:
1. Identify the source system (e.g., a Linux server running a Java app or a network firewall).
2. Access the logging configuration for that system. For a Java application using `log4j2`, locate the `log4j2.xml` file.
3. Define a new socket appender that specifies the IP address of the Elastic Agent and the TCP port you intend to use.
4. If sending structured logs, ensure the layout is set to JSON. Example configuration for `log4j2.xml`:
   ```xml
   <Socket name="ElasticAgent" host="192.168.1.50" port="9002">
       <JsonLayout compact="true" eventEol="true" />
   </Socket>
   ```
5. Ensure that the `eventEol="true"` setting (or equivalent) is used so that every log message is terminated with a newline character. This is critical for the Elastic Agent to identify where one log ends and the next begins.
6. Add the new appender to the `<Loggers>` section of your configuration to activate it.
7. Save the configuration and restart the application or service to apply the changes.
8. Verify the connection by checking the application's local logs for any "Connection Refused" errors.

### For Manual Testing (via CLI):
1. Navigate to the source machine that will be sending the data.
2. Use a tool like `netcat` (`nc`) to verify connectivity and send a test string.
3. Run the command: `echo "Manual test message from source" | nc <AGENT_IP_ADDRESS> 9002`.
4. If the command hangs or returns a timeout, check the network path and firewall settings between the machines.

## Kibana set up steps

1. Log in to Kibana and navigate to **Management > Fleet**.
2. Click on the **Agent policies** tab and select the specific policy assigned to the receiving Elastic Agent.
3. Click **Add integration** and use the search bar to find `Custom TCP Logs`.
4. Click the integration tile and then select **Add Custom TCP Logs**.
5. In the configuration screen, provide a unique **Integration name** such as `production-tcp-receiver`.
6. Set the **Listen Address** to `0.0.0.0` to allow the agent to accept connections on all available network interfaces.
7. Enter the **Listen Port** that matches your vendor configuration (e.g., `9002`).
8. Define the **Data stream dataset** name (e.g., `tcp.generic`) to categorize the incoming logs.
9. (Optional) Under **Advanced Options**, enable **Parse syslog messages** if your source is sending RFC-compliant syslog data.
10. Adjust **Framing** and **Line Delimiter** if your data uses a special character other than the default newline.
11. Click **Save and continue**, then click **Save and deploy changes** to push the configuration to the agents.

# Validation Steps

After configuration is complete, follow these steps to verify data is flowing correctly from the source to the Elastic Stack.

### 1. Trigger Data Flow on Source:
- **Generate Manual Test Event:** From the source host, use a utility like `nc` (netcat) to send a test string: `echo "Verification test message 01" | nc <Agent-IP> 9002`.
- **Trigger System Event:** On a network device, enter and exit the configuration mode or toggle a non-production interface (`shutdown` followed by `no shutdown`) to generate system logs.
- **Restart Log Service:** Restart the source application's logging service to trigger a "service started" log event that should be transmitted over the TCP socket.

### 2. Check Data in Kibana:
1. Navigate to **Analytics > Discover**.
2. Select the `logs-*` data view or the specific integration data view.
3. Enter the following KQL filter: `data_stream.dataset : "tcp.generic"`
4. Verify logs appear in the results. Expand a log entry and confirm these fields are populated:
   - `event.dataset` (should match `tcp.generic`)
   - `source.ip` (the IP address of the vendor source sending the logs)
   - `tcp.port` (the port number the agent received the data on)
   - `message` (containing the raw log payload or the test string sent)
   - `event.ingested` (the timestamp when the data reached the Elastic Stack)
5. Navigate to **Analytics > Dashboards** and search for "Custom TCP Logs" to view any pre-built visualizations.

# Troubleshooting

## Common Configuration Issues

- **Port Already in Use**: If the Elastic Agent fails to start the listener, another process may be using the configured TCP port. Use `netstat -ano | grep <port>` on Linux or `Get-NetTCPConnection -LocalPort <port>` on Windows to identify and stop the conflicting service.
- **Local Firewall Blocking**: The agent host may be rejecting incoming TCP packets. Ensure that the OS-level firewall has an explicit allow rule for the destination port (e.g., `sudo ufw allow 9002/tcp`).
- **Incorrect Listen Address**: Setting the Listen Address to `127.0.0.1` will prevent the agent from accepting connections from external network sources. Ensure it is set to `0.0.0.0` or the specific LAN IP of the agent host.
- **Unapplied Policy Changes**: If changes were made in Kibana but are not taking effect, verify in **Fleet > Agents** that the specific agent shows "Healthy" and has successfully checked in to receive the updated policy.

## Ingestion Errors

- **Framing Failures**: If multiple log events are appearing as a single entry in Discover, the **Line Delimiter** in the integration configuration does not match the delimiter sent by the source. Confirm whether the source uses `\n`, `\r\n`, or a null character.
- **Syslog Parsing Errors**: If "Parse syslog messages" is enabled but fields are not populating correctly, the source may be sending non-compliant syslog data. Check the `error.message` field in Discover for details on why the parser failed.
- **Timestamp Mismatches**: If logs appear with the wrong time, check the **Timezone** setting in the Advanced Options of the integration to ensure it aligns with the source system's clock.

## Vendor Resources

Refer to the official vendor website for additional resources.

## Documentation sites

- [Tcp input plugin | Logstash Reference | Elastic](https://www.elastic.co/guide/en/logstash/8.19/plugins-inputs-tcp.html)
- Refer to the official vendor website for additional documentation.
